{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5653c385",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <img src = \"../banner/banner_ML_UNLP_1900_200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce59794",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/ML_UNLP_Lectures/blob/main/Week02/Notebook_SS02_ModelSelection.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e57de4",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efaa5f-efe9-424e-bf07-c46550bc67fb",
   "metadata": {},
   "source": [
    "The concept behind resampling techniques for evaluating model performance is straightforward: a portion of the data is used to train the model, while the remaining data is used to assess the model's accuracy. \n",
    "\n",
    "This process is repeated several times with different subsets of the data, and the results are averaged and summarized. The primary differences between resampling techniques lie in the method by which the subsets of data are selected. \n",
    "\n",
    "In the following sections, we will discuss the main types of resampling techniques.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a3dcd",
   "metadata": {},
   "source": [
    "# Predicting Wages\n",
    "\n",
    "Our objective today is to construct a model of individual wages\n",
    "\n",
    "$$\n",
    "w = f(X) + u \n",
    "$$\n",
    "\n",
    "where w is the  wage, and X is a matrix that includes potential explanatory variables/predictors. In this problem set, we will focus on a linear model of the form\n",
    "\n",
    "\\begin{align}\n",
    " ln(w) & = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p  + u \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ba2f4",
   "metadata": {},
   "source": [
    "were $ln(w)$ is the logarithm of the wage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdab5a6",
   "metadata": {},
   "source": [
    "Let's load the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516fd2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fae142",
   "metadata": {},
   "source": [
    "and the data set that is a sample of the NLSY97. The NLSY97 is  a nationally representative sample of 8,984 men and women born during the years 1980 through 1984 and living in the United States at the time of the initial survey in 1997.  Participants were ages 12 to 16 as of December 31, 1996.  Interviews were conducted annually from 1997 to 2011 and biennially since then.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2800e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy=pd.read_csv('https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/nlsy97.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e2ca2",
   "metadata": {},
   "source": [
    "what are the predictors that I have available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038f3fa",
   "metadata": {},
   "source": [
    "Let's keep a subset of these predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1086b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy_subset = nlsy[[\"lnw_2016\", \"educ\", \"exp\", \"afqt\", \"mom_educ\", \"dad_educ\"]]\n",
    "nlsy_subset = nlsy_subset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00dbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(nlsy_subset).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476cd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nlsy_subset[[ \"educ\", \"exp\", \"afqt\", \"mom_educ\", \"dad_educ\"]]\n",
    "\n",
    "y=nlsy_subset[[\"lnw_2016\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5aa606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d13f2f",
   "metadata": {},
   "source": [
    "### Best Subset Selection\n",
    "\n",
    "\n",
    "1.  Let $M_0$ denote the null model, which contains no predictors. This\n",
    "    model simply predicts the sample mean for each observation.\n",
    "\n",
    "2.  For $k=1,2,\\dots,p$:\n",
    "\n",
    "    1.  Fit all $\\binom{p}{k}$ models that contain exactly k predictors\n",
    "\n",
    "    2.  Pick the best among these $\\binom{p}{k}$ models, and call it\n",
    "        $M_k$. Where *best* is the one with the smallest $MSE$\n",
    "\n",
    "3.  Select a single best model from among $M_0,\\dots, M_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b1d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d82a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Modelo\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401a4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate MSE    \n",
    "    scores = cross_val_score(model, X[list(feature_set)], y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    # Resultados\n",
    "    mse_scores = -scores  # Convertir a positivo\n",
    "    return {\"model\":feature_set, \"MSE\":mse_scores.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d40adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#import time\n",
    "\n",
    "\n",
    "results = []\n",
    "    \n",
    "for combo in itertools.combinations(X.columns, 2):\n",
    "        results.append(processSubset(combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(results)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models.loc[models['MSE'].argmin()]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae9d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest MSE\n",
    "    best_model = models.loc[models['MSE'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "import time\n",
    "\n",
    "# Could take quite awhile to complete...\n",
    "\n",
    "models_best = pd.DataFrame(columns=[\"MSE\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,5):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79363a5",
   "metadata": {},
   "source": [
    "Now we have one big DataFrame that contains the best models we've generated along with their MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649253e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc741882",
   "metadata": {},
   "outputs": [],
   "source": [
    "2^k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1318f0-248e-41cf-b5c6-3a9fec9f9d99",
   "metadata": {},
   "source": [
    "##  Stepwise Selection\n",
    "\n",
    "-   For computational reasons, best subset selection cannot be applied\n",
    "    with very large p.\n",
    "\n",
    "-   Best subset selection may also suffer from statistical problems when\n",
    "    p is large\n",
    "\n",
    "-   An enormous search space can lead to overfitting and high variance\n",
    "    of the coefficient estimates.\n",
    "\n",
    "-   For both of these reasons, stepwise methods, which explore a far\n",
    "    more restricted set of models, are attractive alternatives to best\n",
    "    subset selection.\n",
    "\n",
    "\n",
    "\n",
    "###  Forward Stepwise Selection\n",
    "\n",
    "    -   Start with no predictors\n",
    "\n",
    "    -   Test all models with 1 predictor. Choose the best model\n",
    "\n",
    "    -   Add 1 predictor at a time, without taking away.\n",
    "\n",
    "    -   Of the p+1 models, choose the one with smallest prediction error\n",
    "        using cross validation\n",
    "        \n",
    "    -   We have $1+ p(p+1)/2$ Models. In best subset we had $2^p$ \n",
    "\n",
    "### Backward Stepwise Selection\n",
    "\n",
    "    -   Same idea but start with a complete model and go backwards,\n",
    "        taking one at a time.\n",
    "\n",
    "\n",
    "### Forward Selection\n",
    "\n",
    "-   Computational advantage over best subset selection is clear.\n",
    "\n",
    "-   It is not guaranteed to find the best possible model out of all\n",
    "    $2^p$ models containing subsets of the p predictors.\n",
    "\n",
    "-   Drawback: once a predictor enters, it cannot leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58092a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictors):\n",
    "\n",
    "    # Pull out predictors we still need to process\n",
    "    remaining_predictors = [p for p in X.columns if p not in predictors]\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in remaining_predictors:\n",
    "        results.append(processSubset(predictors+[p]))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['MSE'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fwd = pd.DataFrame(columns=[\"MSE\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "predictors = []\n",
    "\n",
    "for i in range(1,len(X.columns)+1):    \n",
    "    models_fwd.loc[i] = forward(predictors)\n",
    "    predictors = models_fwd.loc[i][\"model\"]\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42ed3a",
   "metadata": {},
   "source": [
    "### Backward Selection\n",
    "\n",
    "-   Like forward stepwise selection, the backward selection approach\n",
    "    searches through only $1 + p(p + 1)/2$ models\n",
    "\n",
    "-   However, unlike forward stepwise selection, it begins with the model\n",
    "    containing all p predictors, and then iteratively removes the least\n",
    "    useful predictor, one-at-a-time.\n",
    "\n",
    "-   Like forward stepwise selection, backward stepwise selection is not\n",
    "    guaranteed to yield the best model containing a subset of the p\n",
    "    predictors.\n",
    "\n",
    "-   Backward selection requires that the number of observations\n",
    "    (samples) $n$ is larger than the number of variables $p$ (so that\n",
    "    the full model can be fit).\n",
    "\n",
    "-   In contrast, forward stepwise can be used even when $n < p$, and so\n",
    "    is the only viable subset method when p is very large.\n",
    "    \n",
    "Not much has to change to implement backward selection... just looping through the predictors in reverse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8036d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(predictors):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(predictors, len(predictors)-1):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest MSE\n",
    "    best_model = models.loc[models['MSE'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)-1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_bwd = pd.DataFrame(columns=[\"MSE\", \"model\"], index = range(1,len(X.columns)))\n",
    "\n",
    "tic = time.time()\n",
    "predictors = X.columns\n",
    "\n",
    "while(len(predictors) > 1):  \n",
    "    models_bwd.loc[len(predictors)-1] = backward(predictors)\n",
    "    predictors = models_bwd.loc[len(predictors)-1][\"model\"]\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ccfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae56f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fab4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
